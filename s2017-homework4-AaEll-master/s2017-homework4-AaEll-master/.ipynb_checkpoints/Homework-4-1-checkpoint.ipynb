{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Houses in Redfin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To be completed INDIVIDUALLY and due on April 10 at 7pm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we will practice web scraping. Let's get some basic information for each house/apartment in Massachusetts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see houses around Boston University [here](https://www.redfin.com/zipcode/02215)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Information to be scraped](redfin.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each house page, scrape the information of this [house](https://www.redfin.com/MA/Boston/120-Mountfort-St-02215/unit-502/home/11838719), including \n",
    "* full address\n",
    "* price\n",
    "* number of beds\n",
    "* number of baths (full or not)\n",
    "* Sq. Ft (square feet)\n",
    "* price per Sq. Ft\n",
    "* property type\n",
    "* County\n",
    "* community\n",
    "* built\n",
    "* Property details (e.g. dishwasher, elevator, parking, heating, air conditioning, maintenance, etc.)\n",
    "\n",
    "Try to extract as many features as possible. You will use this information in future homework. \n",
    "\n",
    "\n",
    "Save the data in \"house.csv\" in the following format:\n",
    "\n",
    "full address, price, beds, baths, ......\n",
    "\n",
    "**To receive credit, you must commit house.csv to Github.** **(20 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '800x600x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '800x600x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aaron Elliot\n",
    "# ellioa2@bu.edu\n",
    "# U71617701\n",
    "# HW 4.1 4/10/17\n",
    "from selenium import webdriver\n",
    "from pyvirtualdisplay import Display\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "display = Display(visible=0, size=(800, 600))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_RedfinZipCode(zip):\n",
    "    url = 'https://www.redfin.com/zipcode/'+zip\n",
    "    display = Display(visible=0, size=(800, 600))\n",
    "    display.start()\n",
    "    \n",
    "    time.sleep(2+3*random.random())\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #return(driver.current_url)\n",
    "\n",
    "    if driver.current_url == 'https://www.redfin.com/out-of-area-signup':\n",
    "        driver.delete_all_cookies()\n",
    "        return(None)\n",
    "    if driver.find_element_by_class_name('searchAboveTheFold')\\\n",
    "    .find_element_by_xpath(\".//div[@data-rf-test-id='homes-description']\").text == '0 Homes':\n",
    "        driver.delete_all_cookies()\n",
    "        return(None)\n",
    "    \n",
    "    Table = driver.find_element_by_xpath(\"//span[@data-rf-test-name='tableOption']\")\n",
    "    Table.click()\n",
    "    del(Table)\n",
    "\n",
    "    #Webpages = driver.find_element_by_xpath(\"//tr[class='tableRow']\")\n",
    "    Rows = driver.find_elements_by_class_name('tableRow')\n",
    "    WebPages = []\n",
    "    for Row in Rows:\n",
    "        #child = Page.find_elements_by_css_selector(\"*/input[2]\")\n",
    "        child = Row.find_element_by_class_name('col_address')\\\n",
    "                .find_element_by_xpath(\".//a\")\n",
    "        WebPages.append(child.get_attribute('href'))\n",
    "    del(Rows)\n",
    "\n",
    "    DicList= []\n",
    "    \n",
    "    if (random.random()>.9):\n",
    "        time.sleep(3+2*random.random())\n",
    "        driver.get('https://www.redfin.com')\n",
    "    \n",
    "    for Page in WebPages:\n",
    "        housedic = {}\n",
    "        time.sleep(3+4*random.random()) # add some delay to mimic dumb human\n",
    "        driver.get(Page)\n",
    "        MainStats = driver.find_element_by_class_name(\"main-stats\")\n",
    "        \n",
    "        try:\n",
    "            housedic['street_address'] = MainStats.find_element_by_class_name('street-address').get_attribute('title')\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['price'] = MainStats.find_element_by_xpath(\".//span[@itemprop='price']\").get_attribute('content')\\\n",
    "                            +MainStats.find_element_by_xpath(\".//span[@itemprop='priceCurrency']\").get_attribute('content')\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['beds'] = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-beds']\")\\\n",
    "                .find_element_by_class_name(\"statsValue\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['baths'] = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-baths']\")\\\n",
    "            .find_element_by_class_name(\"statsValue\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            SqFt = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-sqFt']\")\n",
    "            housedic['sqft'] = SqFt.find_element_by_class_name(\"statsValue\").text\n",
    "            housedic['price/sqft'] = SqFt.find_element_by_class_name(\"statsLabel\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        KeyDetails = driver.find_element_by_class_name(\"keyDetailsList\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            housedic['prop type'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Property Type')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['county'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'County')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['built'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Built')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        try:\n",
    "            housedic['community'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Community')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "            \n",
    "        try:\n",
    "            details = driver.find_element_by_class_name(\"remarks\").find_element_by_xpath(\".//p\").text\n",
    "            details =  ''.join(filter(lambda l: l.isalpha() or l==' ', details.lower().replace('-',' ')))\n",
    "\n",
    "            if ' parking' in details or ' spot to park' in details:\n",
    "                housedic['parking']=True\n",
    "            if ' air conditioning' in details or ' air conditioned' in details:\n",
    "                housedic['air conditioning']=True    \n",
    "            if 'kitchen' in details or 'cutty cooking room' in details:\n",
    "                housedic['kitchen']=True\n",
    "\n",
    "            details = set(details.split(' '))    \n",
    "            if 'dishwasher' in details or 'dishwashing' in details:\n",
    "                housedic['dishwasher']=True\n",
    "            if 'laundry' in details:\n",
    "                housedic['laundry']=True\n",
    "            if 'heating' in details or 'heated' in details:\n",
    "                housedic['heating']=True\n",
    "            if 'maintenance ' in details:\n",
    "                housedic['maintenance']=True\n",
    "            if 'elevator' in details:\n",
    "                housedic['elevator']=True\n",
    "            if 'stairs' in details:\n",
    "                housedic['stairs']=True\n",
    "            if 'refrigerator' in details or 'refridgerator' in details:\n",
    "                housedic['refrigerator']=True\n",
    "            if 'furnished' in details or 'furnishings' in details:\n",
    "                housedic['furnished']=True\n",
    "        except NoSuchElementException:\n",
    "            X=1\n",
    "        DicList.append(housedic)\n",
    "        if (random.random()>.99):\n",
    "            time.sleep(5+6*random.random())\n",
    "            driver.get('https://www.redfin.com')\n",
    "\n",
    "\n",
    "    driver.delete_all_cookies()\n",
    "    return (DicList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "[{'street_address': '86 Jersey St #42', 'price': '474900USD', 'beds': '1', 'baths': '1', 'sqft': '538', 'price/sqft': '$883 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '1920', 'community': 'The Fenway', 'kitchen': True, 'laundry': True}, {'street_address': '24-30 Peterborough St #23', 'price': '429000USD', 'beds': '1', 'baths': '1', 'sqft': '476', 'price/sqft': '$901 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '1900', 'community': 'The Fenway', 'kitchen': True}, {'street_address': '64 Queensberry St #312', 'price': '369000USD', 'beds': '1', 'baths': '1', 'sqft': '360', 'price/sqft': '$1025 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '1910', 'community': 'Boston', 'kitchen': True, 'dishwasher': True}, {'street_address': '849 Beacon #2', 'price': '549000USD', 'beds': '1', 'baths': '1', 'sqft': '550', 'price/sqft': '$998 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '1920', 'community': 'Boston'}, {'street_address': '566 Commonwealth Ave #1002', 'price': '749900USD', 'beds': '2', 'baths': '2', 'sqft': '1,255', 'price/sqft': '$598 / Sq. Ft.', 'prop type': 'Co-op', 'county': 'Suffolk', 'built': '1968', 'community': 'Kenmore Square', 'parking': True}, {'street_address': '131 Park Dr Unit G2', 'price': '640000USD', 'beds': '3', 'baths': '1', 'sqft': '812', 'price/sqft': '$788 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '1910', 'community': 'The Fenway', 'air conditioning': True, 'kitchen': True, 'dishwasher': True, 'laundry': True, 'heating': True, 'elevator': True}, {'street_address': '188 Brookline Ave Unit 19-2 K', 'price': '1635900USD', 'beds': '2', 'baths': '2', 'sqft': '1,148', 'price/sqft': '$1425 / Sq. Ft.', 'prop type': 'Condominium', 'county': 'Suffolk', 'built': '2018', 'community': 'The Fenway', 'kitchen': True}]\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting\")\n",
    "zip = '02215'\n",
    "DicList = scrape_RedfinZipCode(zip)\n",
    "print(DicList)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing begins\n",
      "writing finished\n"
     ]
    }
   ],
   "source": [
    "print(\"writing begins\")\n",
    "\n",
    "keys = ['street_address','price','beds','baths','sqft','price/sqft',\\\n",
    "    'prop type','county','community','built','parking','air conditioning',\\\n",
    "    'kitchen','dishwasher','laundry','heating','maintenance','elevator',\\\n",
    "    'stairs','refrigerator','furnished']\n",
    "\n",
    "with open('house.csv', 'w') as output_file:\n",
    "    csvWriter = csv.DictWriter(output_file, keys)\n",
    "    csvWriter.writeheader()\n",
    "    csvWriter.writerows(DicList)\n",
    "#del (DicList)\n",
    "print(\"writing finished\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can scrape and extract information of a house, scrape the information of houses in Massachusetts (as of today there are around 10000 houses in MA listed in Redfin). To see all the listings, you can query all the zip codes in Massachusetts. You can see all the zip codes in Massachusetts [here](https://github.com/evimaria/CS506-Spring2007/blob/master/Homeworks/zipcodes.txt).\n",
    "Save the data in \"MA_houses.csv\", one line for each house:\n",
    "**To receive credit, you must commit MA_houses.csv to Github** **(20 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Method 1: finding the CSV's urls\n"
     ]
    }
   ],
   "source": [
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "# X NOT THE FINAL METHOD USED, SCROLL DOWN TO BOTTOM FOR FINAL METHOD X\n",
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "print(\"Starting Method 1: finding the CSV's urls\")\n",
    "#this is not the final method I used please look further for my final method\n",
    "#I was quickly banned and the method does not recognize this\n",
    "# This code was used to construct MA_houses2.csv which I did not commit to the final file\n",
    "\n",
    "from urllib.parse import urljoin  # for Python2: from urlparse import urljoin\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from pyvirtualdisplay import Display\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "display = Display(visible=0, size=(800, 600))\n",
    "display.start()\n",
    "\n",
    "display = Display(visible=0, size=(800, 600))\n",
    "display.start()\n",
    "def get_csv_RedfinZipCode(zip,driver):\n",
    "    url = 'https://www.redfin.com/zipcode/'+zip\n",
    "     \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    time.sleep(random.random())\n",
    "    driver.get(url)\n",
    "    \n",
    "    if driver.current_url != url:\n",
    "        driver.delete_all_cookies()\n",
    "        return(None)\n",
    "    \n",
    "    try: csv_url = urljoin(url, driver.find_element_by_class_name('searchAboveTheFold').\\\n",
    "                      find_element_by_class_name('viewingPage').find_element_by_xpath(\".//a\")\\\n",
    "                      .get_attribute(\"href\"))\n",
    "    except NoSuchElementException:\n",
    "        return (None)\n",
    "    return (csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Check each Zipcode for a CSV and use get_csv_RedfinZipCode to append the address of the csv to csv_urls.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Method 1: Check each Zipcode for a CSV and use get_csv_RedfinZipCode to append the address of the csv to csv_urls.txt\")\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "i=0\n",
    "\n",
    "Empty_Zips = 0\n",
    "Number_of_csv = 0\n",
    "# this one doesnt work\n",
    "with open('csv_urls.txt','w') as csv:\n",
    "    for zip_code in open('zipcodes.txt','r'): \n",
    "        if i>0:\n",
    "            url = get_csv_RedfinZipCode(zip_code.strip(),driver)\n",
    "            if url==None:\n",
    "                Empty_Zips = Empty_Zips + 1\n",
    "                i=i+1\n",
    "                continue\n",
    "            csv.write(str(url))\n",
    "            csv.write('\\n')\n",
    "            Number_of_csv = Number_of_csv + 1\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Request the CSV's w/user_agent and append the data to MA_houses2\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Method 1: Request the CSV's w/user_agent and append the data to MA_houses2\")\n",
    "import requests\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "keys = ['street_address','price','beds','baths','sqft','price/sqft',\\\n",
    "    'prop type','county','community','built','parking','air conditioning',\\\n",
    "    'kitchen','dishwasher','laundry','heating','maintenance','elevator',\\\n",
    "    'stairs','refrigerator','furnished']\n",
    "house_count = 0\n",
    "\n",
    "with open('MA_houses2.csv', 'a') as output_file:\n",
    "    for url in open('csv_urls.txt', 'r'):\n",
    "        r = requests.get(url.strip(), stream=True,headers={'User-Agent': user_agent})\n",
    "        time.sleep(3+random.random()*2)\n",
    "        DicList = []\n",
    "        with open('Failed_zips.csv', 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        with open('Failed_zips.csv','r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for home in reader:\n",
    "                house_count = house_count + 1\n",
    "                Dic = {}\n",
    "                Dic['street_address'] = home[3]\n",
    "                Dic['price'] = home[7]\n",
    "                Dic['beds'] = home[8]\n",
    "                Dic['baths'] = home[9]\n",
    "                Dic['sqft'] = home[11]\n",
    "                Dic['price/sqft'] = home[15]\n",
    "                Dic['prop type'] = home[2]\n",
    "                Dic['built'] = home[13]\n",
    "                DicList.append(Dic)\n",
    "    csvWriter = csv.DictWriter(output_file, keys)\n",
    "    csvWriter.writeheader()\n",
    "    csvWriter.writerows(DicList)\n",
    "                \n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486 02207\n",
      "\n",
      "487 02210\n",
      "\n",
      "488 02211\n",
      "\n",
      "489 02212\n",
      "\n",
      "490 02215\n",
      "\n",
      "491 02216\n",
      "\n",
      "492 02217\n",
      "\n",
      "493 02222\n",
      "\n",
      "494 02228\n",
      "\n",
      "495 02238\n",
      "\n",
      "496 02239\n",
      "\n",
      "497 02241\n",
      "\n",
      "498 02266\n",
      "\n",
      "499 02269\n",
      "\n",
      "500 02283\n",
      "\n",
      "501 02284\n",
      "\n",
      "502 02293\n",
      "\n",
      "503 02295\n",
      "\n",
      "504 02297\n",
      "\n",
      "505 02298\n",
      "\n",
      "506 02301\n",
      "\n",
      "507 02302\n",
      "\n",
      "508 02303\n",
      "\n",
      "509 02304\n",
      "\n",
      "510 02305\n",
      "\n",
      "511 02322\n",
      "\n",
      "512 02324\n",
      "\n",
      "513 02325\n",
      "\n",
      "514 02327\n",
      "\n",
      "515 02330\n",
      "\n",
      "516 02331\n",
      "\n",
      "517 02332\n",
      "\n",
      "518 02333\n",
      "\n",
      "519 02334\n",
      "\n",
      "520 02337\n",
      "\n",
      "521 02338\n",
      "\n",
      "522 02339\n",
      "\n",
      "523 02340\n",
      "\n",
      "524 02341\n",
      "\n",
      "525 02343\n",
      "\n",
      "526 02344\n",
      "\n",
      "527 02345\n",
      "\n",
      "528 02346\n",
      "\n",
      "529 02347\n",
      "\n",
      "530 02348\n",
      "\n",
      "531 02349\n",
      "\n",
      "532 02350\n",
      "\n",
      "533 02351\n",
      "\n",
      "534 02355\n",
      "\n",
      "535 02356\n",
      "\n",
      "536 02357\n",
      "\n",
      "537 02358\n",
      "\n",
      "538 02359\n",
      "\n",
      "539 02360\n",
      "\n",
      "540 02361\n",
      "\n",
      "541 02362\n",
      "\n",
      "542 02364\n",
      "\n",
      "543 02366\n",
      "\n",
      "544 02367\n",
      "\n",
      "545 02368\n",
      "\n",
      "546 02370\n",
      "\n",
      "547 02375\n",
      "\n",
      "548 02379\n",
      "\n",
      "549 02381\n",
      "\n",
      "550 02382\n",
      "\n",
      "551 02420\n",
      "\n",
      "552 02421\n",
      "\n",
      "553 02445\n",
      "\n",
      "554 02446\n",
      "\n",
      "555 02447\n",
      "\n",
      "556 02451\n",
      "\n",
      "557 02452\n",
      "\n",
      "558 02453\n",
      "\n",
      "559 02454\n",
      "\n",
      "560 02455\n",
      "\n",
      "561 02456\n",
      "\n",
      "562 02457\n",
      "\n",
      "563 02458\n",
      "\n",
      "564 02459\n",
      "\n",
      "565 02460\n",
      "\n",
      "566 02461\n",
      "\n",
      "567 02462\n",
      "\n",
      "568 02464\n",
      "\n",
      "569 02465\n",
      "\n",
      "570 02466\n",
      "\n",
      "571 02467\n",
      "\n",
      "572 02468\n",
      "\n",
      "573 02471\n",
      "\n",
      "574 02472\n",
      "\n",
      "575 02474\n",
      "\n",
      "576 02475\n",
      "\n",
      "577 02476\n",
      "\n",
      "578 02477\n",
      "\n",
      "579 02478\n",
      "\n",
      "580 02479\n",
      "\n",
      "581 02481\n",
      "\n",
      "582 02482\n",
      "\n",
      "583 02492\n",
      "\n",
      "584 02493\n",
      "\n",
      "585 02494\n",
      "\n",
      "586 02495\n",
      "\n",
      "587 02532\n",
      "\n",
      "588 02534\n",
      "\n",
      "589 02535\n",
      "\n",
      "590 02536\n",
      "\n",
      "591 02537\n",
      "\n",
      "592 02538\n",
      "\n",
      "593 02539\n",
      "\n",
      "594 02540\n",
      "\n",
      "595 02541\n",
      "\n",
      "596 02542\n",
      "\n",
      "597 02543\n",
      "\n",
      "598 02552\n",
      "\n",
      "599 02553\n",
      "\n",
      "600 02554\n",
      "\n",
      "601 02556\n",
      "\n",
      "602 02557\n",
      "\n",
      "603 02558\n",
      "\n",
      "604 02559\n",
      "\n",
      "605 02561\n",
      "\n",
      "606 02562\n",
      "\n",
      "607 02563\n",
      "\n",
      "608 02564\n",
      "\n",
      "609 02565\n",
      "\n",
      "610 02568\n",
      "\n",
      "611 02571\n",
      "\n",
      "612 02573\n",
      "\n",
      "613 02574\n",
      "\n",
      "614 02575\n",
      "\n",
      "615 02576\n",
      "\n",
      "616 02584\n",
      "\n",
      "617 02601\n",
      "\n",
      "618 02630\n",
      "\n",
      "619 02631\n",
      "\n",
      "620 02632\n",
      "\n",
      "621 02633\n",
      "\n",
      "622 02634\n",
      "\n",
      "623 02635\n",
      "\n",
      "624 02636\n",
      "\n",
      "625 02637\n",
      "\n",
      "626 02638\n",
      "\n",
      "627 02639\n",
      "\n",
      "628 02641\n",
      "\n",
      "629 02642\n",
      "\n",
      "630 02643\n",
      "\n",
      "631 02644\n",
      "\n",
      "632 02645\n",
      "\n",
      "633 02646\n",
      "\n",
      "634 02647\n",
      "\n",
      "635 02648\n",
      "\n",
      "636 02649\n",
      "\n",
      "637 02650\n",
      "\n",
      "638 02651\n",
      "\n",
      "639 02652\n",
      "\n",
      "640 02653\n",
      "\n",
      "641 02655\n",
      "\n",
      "642 02657\n",
      "\n",
      "643 02659\n",
      "\n",
      "644 02660\n",
      "\n",
      "645 02661\n",
      "\n",
      "646 02662\n",
      "\n",
      "647 02663\n",
      "\n",
      "648 02664\n",
      "\n",
      "649 02666\n",
      "\n",
      "650 02667\n",
      "\n",
      "651 02668\n",
      "\n",
      "652 02669\n",
      "\n",
      "653 02670\n",
      "\n",
      "654 02671\n",
      "\n",
      "655 02672\n",
      "\n",
      "656 02673\n",
      "\n",
      "657 02675\n",
      "\n",
      "658 02702\n",
      "\n",
      "659 02703\n",
      "\n",
      "660 02712\n",
      "\n",
      "661 02713\n",
      "\n",
      "662 02714\n",
      "\n",
      "663 02715\n",
      "\n",
      "664 02717\n",
      "\n",
      "665 02718\n",
      "\n",
      "666 02719\n",
      "\n",
      "667 02720\n",
      "\n",
      "668 02721\n",
      "\n",
      "669 02722\n",
      "\n",
      "670 02723\n",
      "\n",
      "671 02724\n",
      "\n",
      "672 02725\n",
      "\n",
      "673 02726\n",
      "\n",
      "674 02738\n",
      "\n",
      "675 02739\n",
      "\n",
      "676 02740\n",
      "\n",
      "677 02741\n",
      "\n",
      "678 02742\n",
      "\n",
      "679 02743\n",
      "\n",
      "680 02744\n",
      "\n",
      "681 02745\n",
      "\n",
      "682 02746\n",
      "\n",
      "683 02747\n",
      "\n",
      "684 02748\n",
      "\n",
      "685 02760\n",
      "\n",
      "686 02761\n",
      "\n",
      "687 02762\n",
      "\n",
      "688 02763\n",
      "\n",
      "689 02764\n",
      "\n",
      "690 02766\n",
      "\n",
      "691 02767\n",
      "\n",
      "692 02768\n",
      "\n",
      "693 02769\n",
      "\n",
      "694 02770\n",
      "\n",
      "695 02771\n",
      "\n",
      "696 02777\n",
      "\n",
      "697 02779\n",
      "\n",
      "698 02780\n",
      "\n",
      "699 02783\n",
      "\n",
      "700 02790\n",
      "\n",
      "701 02791\n",
      "\n",
      "702 05501\n",
      "\n",
      "703 05544\n",
      "\n",
      "703 05544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing space\n",
    "i=-1\n",
    "for zip_code in open('zipcodes.txt','r'):\n",
    "    i=i+1\n",
    "    if i>485:\n",
    "        print(i, zip_code)\n",
    "    Lastzip = zip_code\n",
    "print(i,Lastzip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027\n"
     ]
    }
   ],
   "source": [
    "# Method2: Selenium webdriver, webscraping\n",
    "# This is my best method, it was placed in MAhouses.py and so was not ran from this console\n",
    "# This is the code used to construct MA_houses.csv\n",
    "# At a certain point, their security was able to recognize my script regardless of what tweaks I did,\n",
    "# so I was only able to reach the \n",
    "#!/usr/bin/python\n",
    "\n",
    "from selenium import webdriver\n",
    "from pyvirtualdisplay import Display\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "display = Display(visible=0, size=(800, 600))\n",
    "display.start()\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "def scrape_RedfinZipCode(zip,driver):\n",
    "    url = 'https://www.redfin.com/zipcode/'+zip\n",
    "    \n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    \n",
    "    if (random.random()>.94):\n",
    "        driver.get('https://www.redfin.com')\n",
    "        time.sleep(random.random()+3)\n",
    "     \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(random.random()*2+3)\n",
    "\n",
    "    \n",
    "    # if they redirected me, then skip it\n",
    "    if driver.current_url != url:\n",
    "        driver.delete_all_cookies()\n",
    "        return(None)\n",
    "    \n",
    "    # if the zip has 0 homes in it, then skip it\n",
    "    if driver.find_element_by_class_name('searchAboveTheFold')\\\n",
    "        .find_element_by_xpath(\".//div[@data-rf-test-id='homes-description']\")\\\n",
    "        .text == '0 Homes':\n",
    "        driver.delete_all_cookies()\n",
    "        return(None)\n",
    "    \n",
    "    Table = driver.find_element_by_xpath(\"//span[@data-rf-test-name='tableOption']\")\n",
    "    Table.click()\n",
    "    del(Table)\n",
    "    \n",
    "    # this adds the links of the houses in ZIP to Webpages\n",
    "    Rows = driver.find_elements_by_class_name('tableRow')\n",
    "    WebPages = [] \n",
    "    for Row in Rows:\n",
    "        child = Row.find_element_by_class_name('col_address')\\\n",
    "                .find_element_by_xpath(\".//a\")\n",
    "        WebPages.append(child.get_attribute('href'))\n",
    "    del(Rows)\n",
    "\n",
    "    HouseList = [] # this is our main data structure to append house dictionaries\n",
    "    time.sleep(.5)\n",
    "    # this looks at each house's link and gets the information on it\n",
    "    for Page in WebPages:\n",
    "        housedic = {}\n",
    "        #if (random.random()>.97):\n",
    "        #    driver.get('https://www.redfin.com')\n",
    "        #    time.sleep(random.random()+11)\n",
    "        driver.get(Page)\n",
    "        time.sleep(random.random()*3+1)\n",
    "        MainStats = driver.find_element_by_class_name(\"main-stats\")\n",
    "        \n",
    "        try:\n",
    "            housedic['street_address'] = MainStats.find_element_by_class_name('street-address').get_attribute('title')\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            housedic['price'] = MainStats.find_element_by_xpath(\".//span[@itemprop='price']\").get_attribute('content')\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            housedic['beds'] = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-beds']\")\\\n",
    "                .find_element_by_class_name(\"statsValue\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            housedic['baths'] = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-baths']\")\\\n",
    "            .find_element_by_class_name(\"statsValue\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            SqFt = driver.find_element_by_xpath(\"//div[@data-rf-test-id='abp-sqFt']\")\n",
    "            housedic['sqft'] = SqFt.find_element_by_class_name(\"statsValue\").text\n",
    "            housedic['price/sqft'] = SqFt.find_element_by_class_name(\"statsLabel\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        KeyDetails = driver.find_element_by_class_name(\"keyDetailsList\")\n",
    "\n",
    "        try:\n",
    "            housedic['prop type'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Property Type')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        try:\n",
    "            housedic['county'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'County')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        try:\n",
    "            housedic['built'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Built')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        try:\n",
    "            housedic['community'] = KeyDetails.find_element_by_xpath(\".//*[contains(text(), 'Community')]/following-sibling::*\").text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            details = driver.find_element_by_class_name(\"remarks\").find_element_by_xpath(\".//p\").text\n",
    "            details =  ''.join(filter(lambda l: l.isalpha() or l==' ', details.lower().replace('-',' ')))\n",
    "\n",
    "            if ' parking' in details or ' spot to park' in details:\n",
    "                housedic['parking']=True\n",
    "            if ' air conditioning' in details or ' air conditioned' in details:\n",
    "                housedic['air conditioning']=True    \n",
    "\n",
    "            details = set(details.split(' '))\n",
    "            if 'kitchen' in details:\n",
    "                housedic['kitchen'] = True\n",
    "            if 'dishwasher' in details or 'dishwashing' in details:\n",
    "                housedic['dishwasher'] = True\n",
    "            if 'laundry' in details:\n",
    "                housedic['laundry'] = True\n",
    "            if 'heating' in details or 'heated' in details:\n",
    "                housedic['heating'] = True\n",
    "            if 'elevator' in details:\n",
    "                housedic['elevator'] = True\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        HouseList.append(housedic)\n",
    "    driver.delete_all_cookies()\n",
    "    return (HouseList)\n",
    "\n",
    "print(\"Starting\")\n",
    "\n",
    "keys = ['street_address','price','beds','baths','sqft','price/sqft',\\\n",
    "    'prop type','county','community','built','parking','air conditioning',\\\n",
    "    'kitchen','dishwasher','laundry','heating','elevator']\n",
    "\n",
    "\n",
    "i=-1\n",
    "count_found = 0\n",
    "count_failed = 0\n",
    "\n",
    "with open('MA_houses.csv', 'a') as output_file:\n",
    "    MainCSV = csv.DictWriter(output_file, keys)\n",
    "    for zipcode in open('zipcodes.txt','r'):\n",
    "        i+=1\n",
    "        if i>512: # Whenever their security locked me out, I would manually update this value and reset my IP\n",
    "                  # I usually got around 50 - 200 Zips between resets, but toward the deadline their security\n",
    "                  # suddenly started recognizing me sooner, and so I was only getting around 10 - 20 zips.\n",
    "                    # The 512th Zip was as far as I was able to get. Also I ended up with the zips that I\n",
    "                    # accidentally ran twice, so there are a small number of duplicates in my MA_houses.csv\n",
    "            if (i%98 == 0):\n",
    "                time.sleep(60*3+3 +random.random())\n",
    "                print(\"Coffee break!\")\n",
    "            print(i,zipcode.strip())\n",
    "            DicList = scrape_RedfinZipCode(zipcode.strip(),driver)\n",
    "            if DicList != None:\n",
    "                count_found = count_found+1\n",
    "                MainCSV.writerows(DicList)\n",
    "            else:\n",
    "                count_failed = count_failed+1\n",
    "    \n",
    "print(\"finished\\n\",\"count failed:\",count_failed,\"\\ncount found:\",count_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=199&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=216&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=222&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=238&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=239&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=250&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=10\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=251&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=329&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=347&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=349&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=357&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=358&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=359&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=360&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=361&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=362&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=363&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=13\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=364&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=365&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=366&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=367&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=368&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=369&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=370&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=371&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=372&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=373&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=374&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=13\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=375&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=376&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=11\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=377&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n",
      "https://www.redfin.com/stingray/api/gis-csv?al=1&market=boston&num_homes=350&ord=redfin-recommended-asc&page_number=1&region_id=379&region_type=2&sf=1,2,3,5,6,7&sp=true&status=9&uipt=1,2,3,4,5,6&v=8&zoomLevel=12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# these were the csv url I printed as output before I reorginized the file,\n",
    "# I didnt think it was worth wasting time re-running to have it under the correct code,\n",
    "# but still interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note that many websites will block you if you are sending too many queries. To prevent getting block, you should wait between queries (typically 2-5 seconds). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
